{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T07:08:53.708310Z","iopub.execute_input":"2025-08-07T07:08:53.708554Z","iopub.status.idle":"2025-08-07T07:08:54.055830Z","shell.execute_reply.started":"2025-08-07T07:08:53.708535Z","shell.execute_reply":"2025-08-07T07:08:54.054950Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!git clone https://github.com/zash13/intro-to-ir.git code\n!cd ./code && ls && git lfs pull \n%cd code/src","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T07:08:54.057676Z","iopub.execute_input":"2025-08-07T07:08:54.058086Z","iopub.status.idle":"2025-08-07T07:08:58.288960Z","shell.execute_reply.started":"2025-08-07T07:08:54.058052Z","shell.execute_reply":"2025-08-07T07:08:58.287735Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'code'...\nremote: Enumerating objects: 127, done.\u001b[K\nremote: Counting objects: 100% (127/127), done.\u001b[K\nremote: Compressing objects: 100% (75/75), done.\u001b[K\nremote: Total 127 (delta 54), reused 113 (delta 40), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (127/127), 1.35 MiB | 12.54 MiB/s, done.\nResolving deltas: 100% (54/54), done.\nFiltering content: 100% (2/2), 101.61 MiB | 35.83 MiB/s, done.\ncbow2_loss.png\tdataset\t\tpyrightconfig.json  src\ncbow_loss.png\tloss_curve.png\tREADME.md\n/kaggle/working/code/src\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T07:08:58.290263Z","iopub.execute_input":"2025-08-07T07:08:58.290521Z","iopub.status.idle":"2025-08-07T07:08:58.413692Z","shell.execute_reply.started":"2025-08-07T07:08:58.290497Z","shell.execute_reply":"2025-08-07T07:08:58.412395Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/code/src\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom embeding_model import CBOW2, SkipGram\nfrom collections import Counter\nfrom tqdm import tqdm\n\nBASE_DIR = os.getcwd()\n\nDATASET_PATH = os.path.join(BASE_DIR, \"..\", \"dataset\", \"Text8\", \"text8.txt\")\nDATASET_PATH = os.path.normpath(DATASET_PATH)\n\n\nclass Token:\n    def __init__(self, vocab) -> None:\n        self.special_tokens = {\n            \"<#START>\": 0,\n            \"<#PAD>\": 1,\n            \"<#UNKNOWN>\": 2,\n            \"<#END>\": 3,\n        }\n        self.token_map = self._generate_token_map(vocab)\n\n    def _generate_token_map(self, vocab) -> dict[str, int]:\n        token_map = {\n            word: (idx + len(self.special_tokens)) for idx, word in enumerate(vocab)\n        }\n        return {**self.special_tokens, **token_map}\n\n    def get_token_map(self):\n        return self.token_map\n\n    def tokenize(self, input):\n        result = []\n        for word in input.split():\n            result.append(self.token_map.get(word, self.token_map[\"<#UNKNOWN>\"]))\n        return [self.token_map[\"<#START>\"]] + result + [self.token_map[\"<#END>\"]]\n\n    def binary_vector(self, token_list: list[int]):\n        result_list = np.zeros(len(self.token_map), dtype=int)\n        for token in token_list:\n            if 0 <= token < len(self.token_map):\n                result_list[token] = 1\n\n        return result_list\n\n    @staticmethod\n    def clean_input(input):\n        input = (\n            input.replace(\",\", \"\")\n            .replace(\"!\", \"\")\n            .replace(\"?\", \"\")\n            .replace(\"(\", \"\")\n            .replace(\")\", \"\")\n            .replace(\":\", \"\")\n        )\n        return input\n\n\nclass CSVStorage:\n    @staticmethod\n    def save(df, filename, index=False):\n        df.to_csv(filename, index=index)\n\n    @staticmethod\n    def load(filename):\n        if not os.path.exists(filename):\n            raise FileNotFoundError(f\"The file {filename} does not exist\")\n        return pd.read_csv(filename)\n\n\ndef plot_loss(loss_values, filename=\"loss_curve.png\"):\n    plt.figure(figsize=(10, 6))\n    plt.plot(loss_values, label=\"Training Loss\", color=\"blue\")\n    plt.title(\"Training Loss Over Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.grid(True)\n    plt.legend()\n    plt.savefig(filename)\n    plt.close()\n\n\ndef generate_cbow_skipgram_data(\n    tokenizer: \"Token\", sentences, window_size, vocab_size, model_type=\"cbow\"\n):\n    # if window size is even\n    if window_size % 2 == 0:\n        return False, False\n    half_window = (window_size - 1) / 2\n    half_window = int(half_window)\n    cbow_inputs, cbow_targets = [], []\n    cbow_inputs2, cbow_targets2 = [], []\n    skipgram_inputs, skipgram_targets = [], []\n\n    for sentence in sentences:\n        tokenized = tokenizer.tokenize(sentence)\n        length = len(tokenized)\n\n        # for example if i have 5 word and window_size is 3 , then i will get\n        # pad word0 word1\n        # word0 word1 word2\n        # word1 word2 word3\n        # ....\n        # word4 word5 pad\n        # while always middle word is target\n        # so i will have 5 target (each word have chance to be a target )\n        # len - 2 , case i have 2 pad , in beggening and end\n        for idx in range(half_window, length - 2):\n            context = (\n                tokenized[idx - half_window : idx]\n                + tokenized[idx + 1 : idx + half_window + 1]\n            )\n            target = tokenized[idx]\n\n            binary_vector_input = tokenizer.binary_vector(context)\n            binary_vector_target = tokenizer.binary_vector([target])\n            if model_type == \"cbow\":\n                cbow_inputs.append(binary_vector_input)\n                cbow_targets.append(binary_vector_target)\n                cbow_inputs2.append(context)\n                cbow_targets2.append(target)\n            elif model_type == \"skipgram\":\n                for context_word in context:\n                    skipgram_inputs.append(binary_vector_target)\n                    skipgram_targets.append(binary_vector_input)\n\n    if model_type == \"cbow\":\n        return (cbow_inputs2, cbow_targets2)\n    else:\n        return skipgram_inputs, skipgram_targets\n\n\n# preprocess data\ndata = []\nwith open(DATASET_PATH) as f:\n    data = f.read()\nprint(type(data))\n# output : <class 'str'>\ndata_clean = Token.clean_input(data)\nwords_list = data.lower().split()\nunique_words_list = set(words_list)\nunique_words_list = sorted(unique_words_list)\nvocab = [Token.clean_input(word) for word in unique_words_list]\nvocab = list(set(vocab))\nvocab_size = len(vocab)\nprint(vocab_size, vocab[:10])\n# output : 253854 ['excellite', 'spins', 'supertoys', 'xdarwin', 'neuharth', 'strettodimessina', 'cowpuncher', 'bloomington', 'rounding', 'operaci']\ntokenhelper = Token(vocab)\ntoekn_map = tokenhelper.get_token_map()\nprint(type(toekn_map))\nprint(toekn_map.get(\"excellite\", \" \"))\n# output : <class 'dict'> 187747\n\n# data set hase no abbility to become list of sentences , its just words , without anything that help me to seprate them into sentences\nmax_word = 20  # words per sentence\nchunk_size = 100  # jumber of sentences to process at once\nmin_word_freq = 5\n\n# update 1 :\n# still have problem with size of vocab ,\n# so i try to use tf to find stopwords and words that have low frequency\n#\nstopwords = [\n    \"a\",\n    \"about\",\n    \"above\",\n    \"after\",\n    \"again\",\n    \"against\",\n    \"all\",\n    \"am\",\n    \"an\",\n    \"and\",\n    \"any\",\n    \"are\",\n    \"aren't\",\n    \"as\",\n    \"at\",\n    \"be\",\n    \"because\",\n    \"been\",\n    \"before\",\n    \"being\",\n    \"below\",\n    \"between\",\n    \"both\",\n    \"but\",\n    \"by\",\n    \"can't\",\n    \"cannot\",\n    \"could\",\n    \"couldn't\",\n    \"did\",\n    \"didn't\",\n    \"do\",\n    \"does\",\n    \"doesn't\",\n    \"doing\",\n    \"don't\",\n    \"down\",\n    \"during\",\n    \"each\",\n    \"few\",\n    \"for\",\n    \"from\",\n    \"further\",\n    \"had\",\n    \"hadn't\",\n    \"has\",\n    \"hasn't\",\n    \"have\",\n    \"haven't\",\n    \"having\",\n    \"he\",\n    \"he'd\",\n    \"he'll\",\n    \"he's\",\n    \"her\",\n    \"here\",\n    \"here's\",\n    \"hers\",\n    \"herself\",\n    \"him\",\n    \"himself\",\n    \"his\",\n    \"how\",\n    \"how's\",\n    \"i\",\n    \"i'd\",\n    \"i'll\",\n    \"i'm\",\n    \"i've\",\n    \"if\",\n    \"in\",\n    \"into\",\n    \"is\",\n    \"isn't\",\n    \"it\",\n    \"it's\",\n    \"its\",\n    \"itself\",\n    \"let's\",\n    \"me\",\n    \"more\",\n    \"most\",\n    \"mustn't\",\n    \"my\",\n    \"myself\",\n    \"no\",\n    \"nor\",\n    \"not\",\n    \"of\",\n    \"off\",\n    \"on\",\n    \"once\",\n    \"only\",\n    \"or\",\n    \"other\",\n    \"ought\",\n    \"our\",\n    \"ours\",\n    \"ourselves\",\n    \"out\",\n    \"over\",\n    \"own\",\n    \"same\",\n    \"shan't\",\n    \"she\",\n    \"she'd\",\n    \"she'll\",\n    \"she's\",\n    \"should\",\n    \"shouldn't\",\n    \"so\",\n    \"some\",\n    \"such\",\n    \"than\",\n    \"that\",\n    \"that's\",\n    \"the\",\n    \"their\",\n    \"theirs\",\n    \"them\",\n    \"themselves\",\n    \"then\",\n    \"there\",\n    \"there's\",\n    \"these\",\n    \"they\",\n    \"they'd\",\n    \"they'll\",\n    \"they're\",\n    \"they've\",\n    \"this\",\n    \"those\",\n    \"through\",\n    \"to\",\n    \"too\",\n    \"under\",\n    \"until\",\n    \"up\",\n    \"very\",\n    \"was\",\n    \"wasn't\",\n    \"we\",\n    \"we'd\",\n    \"we'll\",\n    \"we're\",\n    \"we've\",\n    \"were\",\n    \"weren't\",\n    \"what\",\n    \"what's\",\n    \"when\",\n    \"when's\",\n    \"where\",\n    \"where's\",\n    \"which\",\n    \"while\",\n    \"who\",\n    \"who's\",\n    \"whom\",\n    \"why\",\n    \"why's\",\n    \"will\",\n    \"with\",\n    \"won't\",\n    \"would\",\n    \"wouldn't\",\n    \"you\",\n    \"you'd\",\n    \"you'll\",\n    \"you're\",\n    \"you've\",\n    \"your\",\n    \"yours\",\n    \"yourself\",\n    \"yourselves\",\n]\n# update2 : this is so slow , it not work for this many words\n# tf_doc = {word: words_list.count(word) for word in vocab}\nword_counts = Counter(words_list)\ntf_doc = {word: word_counts[word] for word in vocab}\nfor word in tf_doc:\n    if tf_doc.get(word, 0) < min_word_freq:\n        stopwords.append(word)\nstopwords_set = set(stopwords)\nfilter_dataset = [\n    word\n    for word in tqdm(words_list, desc=\"Filtering words\")\n    if word not in stopwords_set\n]\nprint(f\"orginal dataset size {len(words_list)}\")\nprint(f\"filtered dataset size {len(filter_dataset)}\")\n\n\ndef generate_sentences(words, words_per_sentence):\n    for i in range(0, len(words), words_per_sentence):\n        yield \" \".join(words[i : i + words_per_sentence])\n\n\ncbow_model = CBOW2(\n    vocab_size=len(tokenhelper.token_map), window_size=3, embedding_size=300, epoch=20\n)\n\nall_loss = []\nsentence_generator = generate_sentences(filter_dataset, max_word)\n\nwhile True:\n    chunk = []\n    for _ in range(chunk_size):\n        try:\n            chunk.append(next(sentence_generator))\n        except StopIteration:\n            break\n\n    if not chunk:\n        break\n\n    print(\n        f\"Processing chunk of {len(chunk)} sentences -> total words : {len(chunk) * len(chunk[0])}\"\n    )\n\n    cbow_inputs, cbow_targets = generate_cbow_skipgram_data(\n        tokenhelper,\n        chunk,\n        window_size=3,\n        vocab_size=len(tokenhelper.token_map),\n        model_type=\"cbow\",\n    )\n\n    chunk_loss = cbow_model.fit(cbow_inputs, cbow_targets)\n    all_loss.extend(chunk_loss)\n\nplot_loss(all_loss, \"cbow_loss.png\")\ny_pred = cbow_model.predict([\"hello\", \"are\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T07:10:37.985538Z","iopub.execute_input":"2025-08-07T07:10:37.985829Z","execution_failed":"2025-08-07T14:01:06.918Z"}},"outputs":[{"name":"stdout","text":"<class 'str'>\n253854 ['mntv', 'apostelgeschichten', 'toponym', 'chaitya', 'kerin', 'assertive', 'magnifica', 'penchants', 'margravate', 'statuettes']\n<class 'dict'>\n184353\n","output_type":"stream"},{"name":"stderr","text":"Filtering words: 100%|██████████| 17005207/17005207 [00:03<00:00, 5387026.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"orginal dataset size 17005207\nfiltered dataset size 10787112\nProcessing chunk of 100 sentences -> total words : 15200\n(1900, 2) (1900,)\nEpoch 1/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.0365 - loss: 12.4339\nEpoch 2/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.1071 - loss: 12.2830\nEpoch 3/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - accuracy: 0.0770 - loss: 11.7903\nEpoch 4/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.0684 - loss: 10.4727\nEpoch 5/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - accuracy: 0.0713 - loss: 8.7682\nEpoch 6/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - accuracy: 0.1128 - loss: 6.9223\nEpoch 7/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 2s/step - accuracy: 0.1289 - loss: 6.1269\nEpoch 8/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.1455 - loss: 5.5632\nEpoch 9/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.1945 - loss: 5.0515\nEpoch 10/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.1924 - loss: 4.8333\nEpoch 11/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.2445 - loss: 4.4416\nEpoch 12/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.2748 - loss: 4.1277\nEpoch 13/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.3324 - loss: 3.7127\nEpoch 14/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.3674 - loss: 3.3847\nEpoch 15/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.4358 - loss: 3.0135\nEpoch 16/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.5002 - loss: 2.6285\nEpoch 17/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.5885 - loss: 2.3079\nEpoch 18/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.6511 - loss: 1.9605\nEpoch 19/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.7452 - loss: 1.6720\nEpoch 20/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.8036 - loss: 1.4476\nProcessing chunk of 100 sentences -> total words : 14000\n(1900, 2) (1900,)\nEpoch 1/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.0476 - loss: 10.8746\nEpoch 2/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.1417 - loss: 9.3168\nEpoch 3/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.1448 - loss: 8.1748\nEpoch 4/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.2046 - loss: 7.3099\nEpoch 5/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.2100 - loss: 6.6114\nEpoch 6/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.2615 - loss: 5.8597\nEpoch 7/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.2674 - loss: 5.3625\nEpoch 8/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.3011 - loss: 4.7301\nEpoch 9/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.3466 - loss: 4.0975\nEpoch 10/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.3977 - loss: 3.5290\nEpoch 11/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.4533 - loss: 3.0559\nEpoch 12/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.5130 - loss: 2.5164\nEpoch 13/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.5780 - loss: 2.2104\nEpoch 14/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.6635 - loss: 1.8759\nEpoch 15/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.7231 - loss: 1.5936\nEpoch 16/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.7741 - loss: 1.3429\nEpoch 17/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.8361 - loss: 1.1380\nEpoch 18/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.8702 - loss: 0.9912\nEpoch 19/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.8965 - loss: 0.8304\nEpoch 20/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.9162 - loss: 0.7328\nProcessing chunk of 100 sentences -> total words : 15800\n(1900, 2) (1900,)\nEpoch 1/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.0307 - loss: 11.4449\nEpoch 2/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.0863 - loss: 9.7571\nEpoch 3/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.1155 - loss: 8.7381\nEpoch 4/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.1513 - loss: 7.6813\nEpoch 5/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.1880 - loss: 6.8915\nEpoch 6/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.2213 - loss: 6.0186\nEpoch 7/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.2752 - loss: 5.0484\nEpoch 8/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.3330 - loss: 4.2273\nEpoch 9/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.4400 - loss: 3.3456\nEpoch 10/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.4786 - loss: 2.8523\nEpoch 11/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.5738 - loss: 2.3507\nEpoch 12/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 2s/step - accuracy: 0.6527 - loss: 1.9143\nEpoch 13/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.7235 - loss: 1.5832\nEpoch 14/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.7912 - loss: 1.2965\nEpoch 15/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.8311 - loss: 1.0860\nEpoch 16/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.8553 - loss: 0.9294\nEpoch 17/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.8840 - loss: 0.8005\nEpoch 18/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 2s/step - accuracy: 0.8869 - loss: 0.7148\nEpoch 19/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.9118 - loss: 0.5971\nEpoch 20/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.9191 - loss: 0.5667\nProcessing chunk of 100 sentences -> total words : 17000\n(1900, 2) (1900,)\nEpoch 1/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.0831 - loss: 9.9820\nEpoch 2/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.1107 - loss: 8.3221\nEpoch 3/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.1629 - loss: 7.1118\nEpoch 4/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.1924 - loss: 6.2415\nEpoch 5/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - accuracy: 0.2575 - loss: 5.3292\nEpoch 6/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.3152 - loss: 4.7089\nEpoch 7/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.3599 - loss: 4.2067\nEpoch 8/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.4143 - loss: 3.5569\nEpoch 9/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.4958 - loss: 2.9812\nEpoch 10/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.5637 - loss: 2.4919\nEpoch 11/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.6084 - loss: 2.1129\nEpoch 12/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.6845 - loss: 1.6798\nEpoch 13/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.7631 - loss: 1.3777\nEpoch 14/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.8093 - loss: 1.1455\nEpoch 15/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.8842 - loss: 0.7702\nEpoch 17/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.9228 - loss: 0.5607\nEpoch 19/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.9150 - loss: 0.5179\nEpoch 20/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.9381 - loss: 0.4406\nProcessing chunk of 100 sentences -> total words : 15300\n(1900, 2) (1900,)\nEpoch 1/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.0315 - loss: 11.2753\nEpoch 2/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.1163 - loss: 9.2410\nEpoch 3/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.1334 - loss: 8.1897\nEpoch 4/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.1925 - loss: 6.8577\nEpoch 5/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.2559 - loss: 5.7845\nEpoch 6/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.3225 - loss: 4.8279\nEpoch 7/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.3963 - loss: 3.9083\nEpoch 8/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.4774 - loss: 3.1600\nEpoch 9/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.5519 - loss: 2.5018\nEpoch 10/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.6565 - loss: 1.8946\nEpoch 11/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.7179 - loss: 1.5680\nEpoch 12/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.7809 - loss: 1.2780\nEpoch 13/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.8047 - loss: 1.0937\nEpoch 14/20\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.8336 - loss: 0.9328\nEpoch 15/20\n\u001b[1m13/60\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 2s/step - accuracy: 0.8326 - loss: 0.8992","output_type":"stream"}],"execution_count":null}]}